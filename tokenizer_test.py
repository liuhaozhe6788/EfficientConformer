import sentencepiece as spm


tokenizer = spm.SentencePieceProcessor("datasets/LibriSpeech/LibriSpeech_bpe_256.model")
logits = tokenizer.Encode("too")
logits = [[23],[232]]
logits = [  0,   0,   0,   0,   0,   0,   0,   0,   0,  89,   0,   0,   0,   0,
           0,  30,   0, 231,   9,   9, 176, 176, 236,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   7,   0,  65,   0,   0,   0,  23,   0,   0,   0,
          30,   0,  38,   0,  26,  26,   0,   0,   0,   0,   0,   0,  75,   0,
           0,   0,   4,   0,  78,   0, 229, 250,  46,  46,  10,  10,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 108,
           0,   0,   0,   0,   0, 101,   0,   0,   0,   0,  29,   0,   9, 243,
           0,   0,   0,   0,   0,   3,   0,   0,   0,   0,  30,   0, 189,   0,
           0, 246,   0,   0,   0,   0,   0,   0,   0,  21,   0,   0,   0,   0,
           0,  35,   0,   0, 249,   0,  37,  37,   0,   0,  20,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  45,   0,   0, 174,   0,   0,   0,   0,
           0,   0,   0,   0,  23,   0,   6,   0, 114,  98,  98, 239,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0]
words = tokenizer.decode(logits)
pass